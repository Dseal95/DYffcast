{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ConvLSTM` (`roll-out`) Inference.\n",
    "* The aim of this notebook is to run inference on **trained** `ConvLSTM()` models that makes **roll-out** predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import io\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from rainnow.src.convlstm_trainer import create_eval_loader, save_checkpoint, train, validate\n",
    "from rainnow.src.datasets import IMERGDataset\n",
    "from rainnow.src.models.conv_lstm import ConvLSTMModel\n",
    "from rainnow.src.normalise import PreProcess\n",
    "from rainnow.src.plotting import plot_predicted_sequence, plot_training_val_loss\n",
    "from rainnow.src.utilities.loading import load_imerg_datamodule_from_config\n",
    "from rainnow.src.utilities.utils import (\n",
    "   get_device,\n",
    "   transform_minus1_1_to_0_1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Helpers.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** DIR helpers **\n",
    "BASE_PATH = \"/teamspace/studios/this_studio\"\n",
    "\n",
    "CKPT_BASE_PATH = f\"{BASE_PATH}/DYffcast/rainnow/results/\"\n",
    "CONFIGS_BASE_PATH = f\"{BASE_PATH}/DYffcast/rainnow/src/dyffusion/configs/\"\n",
    "\n",
    "CKPT_DIR = \"checkpoints\"\n",
    "CKPT_CFG_NAME = \"hparams.yaml\"\n",
    "DATAMODULE_CONFIG_NAME = \"imerg_precipitation.yaml\"\n",
    "# whether or not to get last.ckpt or to get the \"best model\" ckpt (the other one in the folder).\n",
    "GET_LAST = False\n",
    "\n",
    "# ** Dataloader Params **\n",
    "BATCH_SIZE = 6  # this doesn't matter for inference.\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "INPUT_SEQUENCE_LENGTH = 4\n",
    "OUTPUT_SEQUENCE_LENGTH = 1\n",
    "\n",
    "# ** plotting helpers **\n",
    "# cmap = io.loadmat(\"../../src/utilities/cmaps/colormap.mat\")\n",
    "cmap = io.loadmat(f\"{BASE_PATH}/DYffcast/rainnow/src/utilities/cmaps/colormap.mat\")\n",
    "rain_cmap = ListedColormap(cmap[\"Cmap_rain\"])\n",
    "global_params = {\"font.size\": 8}  # , \"font.family\": \"Times New Roman\"}\n",
    "plt_params = {\"wspace\": 0.1, \"hspace\": 0.15}\n",
    "ylabel_params = {\"ha\": \"right\", \"va\": \"bottom\", \"labelpad\": 1, \"fontsize\": 7.5}\n",
    "\n",
    "# ** get device **\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Datasets & Dataloaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = load_imerg_datamodule_from_config(\n",
    "    cfg_base_path=CONFIGS_BASE_PATH,\n",
    "    cfg_name=DATAMODULE_CONFIG_NAME,\n",
    "    overrides={\n",
    "        \"boxes\": [\"1,0\"],\n",
    "        \"window\": 1,\n",
    "        \"horizon\": 8,\n",
    "        \"prediction_horizon\": 8,\n",
    "        \"sequence_dt\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "# get the .data_<split>\n",
    "# datamodule.setup(\"validate\")\n",
    "datamodule.setup(\"test\")\n",
    "datamodule.setup(\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets.\n",
    "# val_dataset = IMERGDataset(\n",
    "#     datamodule, \"validate\", sequence_length=INPUT_SEQUENCE_LENGTH, target_length=OUTPUT_SEQUENCE_LENGTH\n",
    "# )\n",
    "test_dataset = IMERGDataset(\n",
    "    datamodule, \"test\", sequence_length=INPUT_SEQUENCE_LENGTH, target_length=OUTPUT_SEQUENCE_LENGTH\n",
    ")\n",
    "predict_dataset = IMERGDataset(\n",
    "    datamodule, \"predict\", sequence_length=INPUT_SEQUENCE_LENGTH, target_length=OUTPUT_SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "# instantiate the dataloaders.\n",
    "# val_loader = DataLoader(\n",
    "#     dataset=val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False\n",
    "# )\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False\n",
    ")\n",
    "predict_loader = DataLoader(\n",
    "    dataset=predict_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Instantiate a preproccessor object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** instantiate the preprocesser obj **\n",
    "pprocessor = PreProcess(\n",
    "    percentiles=datamodule.normalization_hparams[\"percentiles\"],\n",
    "    minmax=datamodule.normalization_hparams[\"min_max\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Instantiate a ConvLSTM()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rollout ConvLSTM models.\n",
    "ckpt_ids = {\n",
    "    # ** LCB **\n",
    "    \"convlstm-abcd1234\": \"I4:T1 | hs=(128, 128), ks=(5, 5), dp=.15 [20E, lr=3e-4] BS=12 LPIPS.\",\n",
    "    \"conv_lstm_f1dlb0m7\": \"I4:T1 | hs=(128, 128), ks=(5, 5), dp=.4 [30E, lr=7e-5] BS=12 reversal=15% LPIPS.\",\n",
    "    \"conv_lstm_9h86gnt5\": \"I4:T1 | hs=(128, 128), ks=(5, 5), dp=.40 [20E, lr=7e-5] BS=12 reveral=20% LPIPS.\",\n",
    "    \"conv_lstm_wwj6eryz\": \"I4:T1 | hs=(128, 128), ks=(5, 5), dp=.40 [10E, lr=7e-5] BS=12 reveral=20% LPIPS.\",\n",
    "    \"conv_lstm_i93g6pzb\": \"I4:T1 | hs=(128, 128), ks=(5, 5), dp=.45 [10E, lr=3e-4] BS=24 reveral=20% LPIPS.\",\n",
    "    # ** BCE **\n",
    "    \"convlstm-a8kwo8jx\": \"I4:T1 | hs=(128, 128), ks=(5, 5), dp=.15 [20E, lr=3e-4] BS=12 BCE.\",\n",
    "    \"conv_lstm_k34y14il\": \"I4:T1 | hs=(128, 128), ks=(5, 5), dp=.4 [10E, lr=7e-5] BS=12 BCE.\",\n",
    "}\n",
    "\n",
    "for k, v in ckpt_ids.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** load in checkpoint **\n",
    "ckpt_id = \"convlstm-abcd1234\"\n",
    "# model_save_path = Path(\n",
    "#     os.path.join(CKPT_BASE_PATH, \"convlstm_experiments\", ckpt_id, \"checkpoints\", f\"{ckpt_id}.pt\")\n",
    "# )\n",
    "model_save_path = Path(os.path.join(BASE_PATH, f\"{ckpt_id}.pt\"))\n",
    "\n",
    "assert os.path.exists(model_save_path)\n",
    "model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** instantiate a new model **\n",
    "KERNEL_SIZE = (5, 5)\n",
    "INPUT_DIMS = (1, 128, 128)  # C, H, W\n",
    "OUTPUT_CHANNELS = 1\n",
    "HIDDEN_CHANNELS = [128, 128]\n",
    "NUM_LAYERS = 2\n",
    "CELL_DROPOUT = 0.15\n",
    "\n",
    "# MAKE SURE TO HAVE THE CORRECT OUTPUT ACTIVATION ON THE CONV LSTM.\n",
    "OUTPUT_ACTIVATION = nn.Tanh()  # nn.Sigmoid()\n",
    "\n",
    "model = ConvLSTMModel(\n",
    "    input_sequence_length=INPUT_SEQUENCE_LENGTH,\n",
    "    output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
    "    input_dims=INPUT_DIMS,\n",
    "    hidden_channels=HIDDEN_CHANNELS,\n",
    "    output_channels=OUTPUT_CHANNELS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    output_activation=OUTPUT_ACTIVATION,\n",
    "    apply_batchnorm=True,\n",
    "    cell_dropout=CELL_DROPOUT,\n",
    "    bias=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# load in the checkpoint.\n",
    "model.load_state_dict(\n",
    "    state_dict=torch.load(model_save_path, map_location=torch.device(device))[\"model_state_dict\"]\n",
    ")\n",
    "\n",
    "# set model into eval mode.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Get inputs, X and predict.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** create the eval dataloader **\n",
    "eval_loader, _ = create_eval_loader(\n",
    "    data_loader=predict_loader, horizon=8, input_sequence_length=4, img_dims=(128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for e, (X, target) in enumerate(eval_loader[:1]):\n",
    "        predictions = {}\n",
    "        # predict t+1\n",
    "        _input = X.clone().unsqueeze(0).to(device)\n",
    "\n",
    "        for t in range(target.size(0)):\n",
    "            pred = model(_input)\n",
    "            if isinstance(model.output_activation, nn.Tanh):\n",
    "                pred = transform_minus1_1_to_0_1(pred)\n",
    "\n",
    "            predictions[f\"t{t+1}\"] = pred.squeeze(0)\n",
    "\n",
    "            # update the inputs with the last pred.\n",
    "            _input = torch.concat([_input[:, 1:, ...], pred], dim=1)\n",
    "\n",
    "        results.append([target, predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "figsize = (14, 4)\n",
    "plot_params = {\"cmap\": rain_cmap, \"vmin\": 0.5, \"vmax\": 18}\n",
    "idx = 0\n",
    "targets, predictions = results[idx]\n",
    "targets = targets.cpu().detach()\n",
    "predictions = {k: v.cpu().detach() for k, v in predictions.items()}\n",
    "\n",
    "# get raw scale.\n",
    "target_reversed = pprocessor.reverse_processing(targets).cpu().detach()\n",
    "preds_reversed = {k: pprocessor.reverse_processing(v) for k, v in predictions.items()}\n",
    "\n",
    "fig, axs = plt.subplots(2, targets.size(0), figsize=figsize)\n",
    "plt.rcParams.update(global_params)\n",
    "# plot ground truth in the 1st row.\n",
    "for j in range(targets.size(0)):\n",
    "    axs[0, j].imshow(targets[j, c, ...], **{\"cmap\": rain_cmap})\n",
    "    axs[0, j].set_title(f\"Ground Truth: x_t+{j}\")\n",
    "# plot predictions.\n",
    "for e, (k, pred) in enumerate(predictions.items()):\n",
    "    axs[1, e].imshow(pred[0, c, :, :], **{\"cmap\": rain_cmap})\n",
    "    axs[1, e].set_title(f\"{k}\")\n",
    "for ax in axs.flatten():\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# raw scale.\n",
    "fig, axs = plt.subplots(2, targets.size(0), figsize=figsize)\n",
    "plt.rcParams.update(global_params)\n",
    "# plot ground truth in the 1st row.\n",
    "for j in range(targets.size(0)):\n",
    "    axs[0, j].imshow(target_reversed[j, c, ...], **plot_params)\n",
    "    axs[0, j].set_title(f\"Ground Truth: x_t+{j}\")\n",
    "# plot predictions.\n",
    "for e, (k, pred) in enumerate(preds_reversed.items()):\n",
    "    axs[1, e].imshow(pred[0, c, :, :], **plot_params)\n",
    "    axs[1, e].set_title(f\"{k}\")\n",
    "for ax in axs.flatten():\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF SCRIPT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irp_rain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
