{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ConvLSTM` Evaluation 101\n",
    "* the aim of this notebook is to evaluate trained ConvLSTM models.\n",
    "* 2 evaluations take place in this NB, the first is a sequence to sequence evaluation and the second is CSI (and LPIPS) / time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xarray as xr\n",
    "import xskillscore as xs\n",
    "from livelossplot import PlotLosses\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import io\n",
    "from torch.nn import L1Loss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.image import LearnedPerceptualImagePatchSimilarity as LPIPS\n",
    "from torchmetrics.regression import CriticalSuccessIndex\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rainnow.src.conv_lstm_utils import (\n",
    "    IMERGDataset,\n",
    "    create_eval_loader,\n",
    "    plot_predicted_sequence,\n",
    "    save_checkpoint,\n",
    "    train,\n",
    "    validate,\n",
    ")\n",
    "from rainnow.src.loss import CBLoss, LPIPSMSELoss\n",
    "from rainnow.src.models.conv_lstm import ConvLSTMModel\n",
    "from rainnow.src.normalise import PreProcess\n",
    "from rainnow.src.utilities.loading import load_imerg_datamodule_from_config\n",
    "from rainnow.src.utilities.utils import (\n",
    "    get_device,\n",
    "    transform_0_1_to_minus1_1,\n",
    "    transform_minus1_1_to_0_1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `helpers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available! (device = cpu)\n"
     ]
    }
   ],
   "source": [
    "# ** plotting helpers **\n",
    "cmap = io.loadmat(\"../../src/utilities/cmaps/colormap.mat\")\n",
    "# cmap = io.loadmat(\"/teamspace/studios/this_studio/irp-ds423/rainnow/src/utilities/cmaps/colormap.mat\")\n",
    "rain_cmap = ListedColormap(cmap[\"Cmap_rain\"])\n",
    "global_params = {\"font.size\": 8}  # , \"font.family\": \"Times New Roman\"}\n",
    "plt_params = {\"wspace\": 0.1, \"hspace\": 0.15}\n",
    "ylabel_params = {\"ha\": \"right\", \"va\": \"bottom\", \"labelpad\": 1, \"fontsize\": 7.5}\n",
    "\n",
    "# ** get device **\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** DIR helpers **\n",
    "CKPT_BASE_PATH = \"/Users/ds423/git_uni/irp-ds423/rainnow/results/\"\n",
    "CONFIGS_BASE_PATH = \"/Users/ds423/git_uni/irp-ds423/rainnow/src/dyffusion/configs/\"\n",
    "# CKPT_BASE_PATH = \"/teamspace/studios/this_studio/irp-ds423/rainnow/results/\"\n",
    "# CONFIGS_BASE_PATH = \"/teamspace/studios/this_studio/irp-ds423/rainnow/src/dyffusion/configs/\"\n",
    "\n",
    "CKPT_DIR = \"checkpoints\"\n",
    "CKPT_CFG_NAME = \"hparams.yaml\"\n",
    "DATAMODULE_CONFIG_NAME = \"imerg_precipitation.yaml\"\n",
    "# whether or not to get last.ckpt or to get the \"best model\" ckpt (the other one in the folder).\n",
    "GET_LAST = False\n",
    "\n",
    "# ** Dataloader Params **\n",
    "BATCH_SIZE = 12\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "INPUT_SEQUENCE_LENGTH = 4\n",
    "OUTPUT_SEQUENCE_LENGTH = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Instantiate + Load in the datamodule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-29 10:49:29][imerg_precipitation.py][INFO] --> training, validation & test using 4 (i, j) boxes: ['0,0', '1,0', '2,0', '2,1'].\n",
      "[2024-08-29 10:49:29][imerg_precipitation.py][INFO] --> test data split: [202307010000, 202401010000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-29 10:49:35][torch_datasets.py][INFO] --> creating TEST tensor dataset.\n",
      "[2024-08-29 10:49:36][normalise.py][INFO] --> pprocessing w/ percentiles (1st, 99th): [0.0, 5.670000076293945],  (min, max): [0.0, 3.23434630590838]\n",
      "[2024-08-29 10:49:36][abstract_datamodule.py][INFO] -->  Dataset test size: 984\n"
     ]
    }
   ],
   "source": [
    "datamodule = load_imerg_datamodule_from_config(\n",
    "    cfg_base_path=CONFIGS_BASE_PATH,\n",
    "    cfg_name=DATAMODULE_CONFIG_NAME,\n",
    "    overrides={\n",
    "        \"boxes\": [\"0,0\", \"1,0\", \"2,0\", \"2,1\"],\n",
    "        \"window\": 1,\n",
    "        \"horizon\": 8,\n",
    "        \"prediction_horizon\": 8,\n",
    "        \"sequence_dt\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "datamodule.setup(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Create the test_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets.\n",
    "test_dataset = IMERGDataset(\n",
    "    datamodule, \"test\", sequence_length=INPUT_SEQUENCE_LENGTH, target_length=OUTPUT_SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Instantiate the preprocessor object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-29 10:49:36][normalise.py][INFO] --> pprocessing w/ percentiles (1st, 99th): [0.0, 5.670000076293945],  (min, max): [0.0, 3.23434630590838]\n"
     ]
    }
   ],
   "source": [
    "# ** instantiate the preprocesser obj **\n",
    "pprocessor = PreProcess(\n",
    "    percentiles=datamodule.normalization_hparams[\"percentiles\"],\n",
    "    minmax=datamodule.normalization_hparams[\"min_max\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Get Metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate metrics.\n",
    "lpips = LPIPS(reduction=\"mean\", normalize=True).to(\n",
    "    device\n",
    ")  # set to True so that the function normalises to [-1, 1].\n",
    "mse = MSELoss(reduction=\"mean\")\n",
    "csi_nodes = [2, 10, 18]\n",
    "# need to get the nodes to the same scale as the data. See NB:  imerg_rainfall_classes.ipynb for rain classes + distributions.\n",
    "normed_csi_nodes = pprocessor.apply_preprocessing(np.array(csi_nodes))\n",
    "csi2 = CriticalSuccessIndex(threshold=normed_csi_nodes[0]).to(device)\n",
    "csi10 = CriticalSuccessIndex(threshold=normed_csi_nodes[1]).to(device)\n",
    "csi18 = CriticalSuccessIndex(threshold=normed_csi_nodes[-1]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Evaluation Metrics (entire predictions)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** eval loader (INFO) **\n",
      "Num samples = 1228 w/ dims: torch.Size([12, 1, 128, 128])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ** create the eval dataloader **\n",
    "eval_loader, _ = create_eval_loader(\n",
    "    data_loader=test_loader, horizon=8, input_sequence_length=4, img_dims=(128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvLSTM params (make sure that they match up with the model checkpoint).\n",
    "KERNEL_SIZE = (5, 5)\n",
    "INPUT_DIMS = (1, 128, 128)  # C, H, W\n",
    "OUTPUT_CHANNELS = 1\n",
    "HIDDEN_CHANNELS = [128, 128]\n",
    "NUM_LAYERS = 2\n",
    "CELL_DROPOUT = 0.15\n",
    "OUTPUT_ACTIVATION = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ckpt from /teamspace/studios/this_studio/irp-ds423/rainnow/results/convlstm-abcd1234/checkpoints/convlstm-abcd1234.pt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model convlstm-abcd1234:   0%|          | 0/1228 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model convlstm-abcd1234: 100%|██████████| 1228/1228 [03:28<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ckpt from /teamspace/studios/this_studio/irp-ds423/rainnow/results/convlstm-a8kwo8jx/checkpoints/convlstm-a8kwo8jx.pt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model convlstm-a8kwo8jx: 100%|██████████| 1228/1228 [03:33<00:00,  5.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>lpips</th>\n",
       "      <th>csi2</th>\n",
       "      <th>csi10</th>\n",
       "      <th>csi18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>convlstm-abcd1234</th>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.271863</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.027456</td>\n",
       "      <td>0.010403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convlstm-a8kwo8jx</th>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.388150</td>\n",
       "      <td>0.051441</td>\n",
       "      <td>0.045088</td>\n",
       "      <td>0.025306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MSE     lpips      csi2     csi10     csi18\n",
       "convlstm-abcd1234  0.008475  0.271863  0.139650  0.027456  0.010403\n",
       "convlstm-a8kwo8jx  0.002414  0.388150  0.051441  0.045088  0.025306"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ** evaluate 101 **\n",
    "eval_metrics = {}\n",
    "for ckpt_id in [\n",
    "    \"convlstm-abcd1234\",  # original model ckpt: conv_lstm_hc_128128_ks_5_oa_Tanh.pt\n",
    "    \"convlstm-a8kwo8jx\",\n",
    "]:\n",
    "    # create the model ckpt path.\n",
    "    ckpt_id_path = Path(os.path.join(CKPT_BASE_PATH, \"\", ckpt_id, \"checkpoints\", f\"{ckpt_id}.pt\"))\n",
    "    print(f\"Loading model ckpt from {ckpt_id_path}.\")\n",
    "\n",
    "    # instantiate a new ConvLSTM model.\n",
    "    model = ConvLSTMModel(\n",
    "        input_sequence_length=INPUT_SEQUENCE_LENGTH,\n",
    "        output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
    "        input_dims=INPUT_DIMS,\n",
    "        hidden_channels=HIDDEN_CHANNELS,\n",
    "        output_channels=OUTPUT_CHANNELS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        kernel_size=KERNEL_SIZE,\n",
    "        output_activation=OUTPUT_ACTIVATION,\n",
    "        apply_batchnorm=True,\n",
    "        cell_dropout=CELL_DROPOUT,\n",
    "        bias=True,\n",
    "        device=device,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # load in the checkpoint + set to eval() mode.\n",
    "    model.load_state_dict(\n",
    "        state_dict=torch.load(ckpt_id_path, map_location=torch.device(device))[\"model_state_dict\"]\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    # ** get preds / target pairs **\n",
    "    # loop through the custom eval_loader and get the predictions and targets for each X, target pair.\n",
    "    # at the end of this loop, you have a results list that contains [target, predictions] pairs.\n",
    "    with torch.no_grad():\n",
    "        results = []\n",
    "        for e, (X, target) in tqdm(\n",
    "            enumerate(eval_loader), total=len(eval_loader), desc=f\"Evaluating model {ckpt_id}\"\n",
    "        ):  # enumerate(eval_loader):\n",
    "            predictions = {}\n",
    "            _input = X.clone().unsqueeze(0).to(device)\n",
    "            for t in range(target.size(0)):\n",
    "                pred = model(_input)  # predict t+1\n",
    "                if isinstance(model.output_activation, nn.Tanh):\n",
    "                    pred = transform_minus1_1_to_0_1(pred)\n",
    "\n",
    "                # add t+i to the predictions.\n",
    "                predictions[f\"t{t+1}\"] = pred.squeeze(0)\n",
    "                # update the inputs with the last pred (auto-regressive rollout)\n",
    "                _input = torch.concat([_input[:, 1:, ...], pred], dim=1)\n",
    "\n",
    "            results.append([target, predictions])\n",
    "\n",
    "        # ** calculate metrics for each preds / target pair **\n",
    "        # reset metrics for eack ckpt id.\n",
    "        # overall metrics for target and prediction.\n",
    "        l2_score = 0\n",
    "        lpips_score = 0\n",
    "        csi2_score = 0  # low rain.\n",
    "        csi10_score = 0  # mid rain.\n",
    "        csi18_score = 0  # heavy rain.\n",
    "        for targets, predictions in results:\n",
    "            # concat to get entire sequence.\n",
    "            pred_seq = torch.cat([v for _, v in predictions.items()], dim=0)\n",
    "\n",
    "            # get metrics.\n",
    "            l2_score += mse(pred_seq.to(device), targets.to(device))\n",
    "            # lpips score. Inputs need to have 3 channels.\n",
    "            lpips_score += lpips(\n",
    "                torch.clamp(pred_seq.expand(-1, 3, -1, -1), 0, 1).to(device),\n",
    "                torch.clamp(targets.expand(-1, 3, -1, -1), 0, 1).to(device),\n",
    "            )\n",
    "            # csi score at different thresholds.\n",
    "            csi2_score += csi2(pred_seq.to(device), targets.to(device))\n",
    "            csi10_score += csi10(pred_seq.to(device), targets.to(device))\n",
    "            csi18_score += csi18(pred_seq.to(device), targets.to(device))\n",
    "\n",
    "        eval_metrics[ckpt_id] = {\n",
    "            \"MSE\": l2_score.item() / len(eval_loader),\n",
    "            \"lpips\": lpips_score.item() / len(eval_loader),\n",
    "            \"csi2\": csi2_score.item() / len(eval_loader),\n",
    "            \"csi10\": csi10_score.item() / len(eval_loader),\n",
    "            \"csi18\": csi18_score.item() / len(eval_loader),\n",
    "        }\n",
    "\n",
    "# create df, format it and export it to a .csv.\n",
    "df_results = pd.DataFrame(eval_metrics).T\n",
    "df_results[[\"MSE\", \"lpips\", \"csi2\", \"csi10\", \"csi18\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Eval Metrics (CSI / t)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ckpt from /teamspace/studios/this_studio/irp-ds423/rainnow/results/convlstm-abcd1234/checkpoints/convlstm-abcd1234.pt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model convlstm-abcd1234:   0%|          | 2/1228 [00:00<03:00,  6.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model convlstm-abcd1234: 100%|██████████| 1228/1228 [03:30<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ckpt from /teamspace/studios/this_studio/irp-ds423/rainnow/results/convlstm-a8kwo8jx/checkpoints/convlstm-a8kwo8jx.pt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model convlstm-a8kwo8jx: 100%|██████████| 1228/1228 [03:29<00:00,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_metrics_per_t = {}\n",
    "for ckpt_id in [\n",
    "    \"convlstm-abcd1234\",  # original model ckpt: conv_lstm_hc_128128_ks_5_oa_Tanh.pt\n",
    "    \"convlstm-a8kwo8jx\",\n",
    "]:\n",
    "    # create the model ckpt path.\n",
    "    ckpt_id_path = Path(os.path.join(CKPT_BASE_PATH, \"\", ckpt_id, \"checkpoints\", f\"{ckpt_id}.pt\"))\n",
    "    print(f\"Loading model ckpt from {ckpt_id_path}.\")\n",
    "\n",
    "    # instantiate a new ConvLSTM model.\n",
    "    model = ConvLSTMModel(\n",
    "        input_sequence_length=INPUT_SEQUENCE_LENGTH,\n",
    "        output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
    "        input_dims=INPUT_DIMS,\n",
    "        hidden_channels=HIDDEN_CHANNELS,\n",
    "        output_channels=OUTPUT_CHANNELS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        kernel_size=KERNEL_SIZE,\n",
    "        output_activation=OUTPUT_ACTIVATION,\n",
    "        apply_batchnorm=True,\n",
    "        cell_dropout=CELL_DROPOUT,\n",
    "        bias=True,\n",
    "        device=device,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # load in the checkpoint + set to eval() mode.\n",
    "    model.load_state_dict(\n",
    "        state_dict=torch.load(ckpt_id_path, map_location=torch.device(device))[\"model_state_dict\"]\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    # ** get preds / target pairs **\n",
    "    # loop through the custom eval_loader and get the predictions and targets for each X, target pair.\n",
    "    # at the end of this loop, you have a results list that contains [target, predictions] pairs.\n",
    "    with torch.no_grad():\n",
    "        results = []\n",
    "        for e, (X, target) in tqdm(\n",
    "            enumerate(eval_loader), total=len(eval_loader), desc=f\"Evaluating model {ckpt_id}\"\n",
    "        ):  # enumerate(eval_loader):\n",
    "            predictions = {}\n",
    "            _input = X.clone().unsqueeze(0).to(device)\n",
    "            for t in range(target.size(0)):\n",
    "                pred = model(_input)  # predict t+1\n",
    "                if isinstance(model.output_activation, nn.Tanh):\n",
    "                    pred = transform_minus1_1_to_0_1(pred)\n",
    "\n",
    "                # add t+i to the predictions.\n",
    "                predictions[f\"t{t+1}\"] = pred.squeeze(0)\n",
    "                # update the inputs with the last pred (auto-regressive rollout)\n",
    "                _input = torch.concat([_input[:, 1:, ...], pred], dim=1)\n",
    "\n",
    "            results.append([target, predictions])\n",
    "\n",
    "        # create csi stores.\n",
    "        csi2_score_t = torch.zeros(target.size(0)).to(device)\n",
    "        csi10_score_t = torch.zeros(target.size(0)).to(device)\n",
    "        csi18_score_t = torch.zeros(target.size(0)).to(device)\n",
    "\n",
    "        # perceptual loss scores.\n",
    "        lpips_score_t = torch.zeros(target.size(0)).to(device)\n",
    "\n",
    "        for targets, predictions in results:\n",
    "            for e, (k, v) in enumerate(predictions.items()):\n",
    "                # loop through all the ts and compute the relevant CSI scores.\n",
    "                csi2_score_t[e] += csi2(targets[e].to(device), v[0, ...].to(device))\n",
    "                csi10_score_t[e] += csi10(targets[e].to(device), v[0, ...].to(device))\n",
    "                csi18_score_t[e] += csi18(targets[e].to(device), v[0, ...].to(device))\n",
    "\n",
    "                lpips_score_t[e] += lpips(\n",
    "                    torch.clamp(targets[e].expand(1, 3, -1, -1), 0, 1).to(device),\n",
    "                    torch.clamp(v[0, ...].expand(1, 3, -1, -1), 0, 1).to(device),\n",
    "                )\n",
    "\n",
    "        # normalise the scores.\n",
    "        eval_metrics_per_t[ckpt_id] = {\n",
    "            \"csi2_t\": csi2_score_t / len(eval_loader),\n",
    "            \"csi10_t\": csi10_score_t / len(eval_loader),\n",
    "            \"csi18_t\": csi18_score_t / len(eval_loader),\n",
    "            \"lpips_t\": lpips_score_t / len(eval_loader),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 8\n",
    "\n",
    "# get csi + lpips dfs.\n",
    "df_all = {}\n",
    "for k, v in eval_metrics_per_t.items():\n",
    "    dfs = {}\n",
    "    for metric, values in v.items():\n",
    "        dfs[metric] = pd.DataFrame(\n",
    "            data=[[i.item() for i in values]], columns=[f\"t{i+1}\" for i in range(len(values))]\n",
    "        )\n",
    "    df_all[k] = dfs\n",
    "\n",
    "df_csi2 = pd.DataFrame(columns=[f\"t{i+1}\" for i in range(horizon)])\n",
    "df_csi10 = pd.DataFrame(columns=[f\"t{i+1}\" for i in range(horizon)])\n",
    "df_csi18 = pd.DataFrame(columns=[f\"t{i+1}\" for i in range(horizon)])\n",
    "df_lpips = pd.DataFrame(columns=[f\"t{i+1}\" for i in range(horizon)])\n",
    "\n",
    "for model_name, metrics in df_all.items():\n",
    "    model_name_clean = model_name.rsplit(\".\", 1)[0]\n",
    "\n",
    "    csi2_values = metrics[\"csi2_t\"].iloc[0].values\n",
    "    csi10_values = metrics[\"csi10_t\"].iloc[0].values\n",
    "    csi18_values = metrics[\"csi18_t\"].iloc[0].values\n",
    "    lpips_values = metrics[\"lpips_t\"].iloc[0].values\n",
    "\n",
    "    df_csi2.loc[model_name_clean] = csi2_values\n",
    "    df_csi10.loc[model_name_clean] = csi10_values\n",
    "    df_csi18.loc[model_name_clean] = csi18_values\n",
    "    df_lpips.loc[model_name_clean] = lpips_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>convlstm-abcd1234</th>\n",
       "      <td>0.410601</td>\n",
       "      <td>0.256862</td>\n",
       "      <td>0.177228</td>\n",
       "      <td>0.132327</td>\n",
       "      <td>0.102480</td>\n",
       "      <td>0.089132</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.070240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convlstm-a8kwo8jx</th>\n",
       "      <td>0.184380</td>\n",
       "      <td>0.080505</td>\n",
       "      <td>0.047988</td>\n",
       "      <td>0.031930</td>\n",
       "      <td>0.020539</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.007031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         t1        t2        t3        t4        t5        t6  \\\n",
       "convlstm-abcd1234  0.410601  0.256862  0.177228  0.132327  0.102480  0.089132   \n",
       "convlstm-a8kwo8jx  0.184380  0.080505  0.047988  0.031930  0.020539  0.014534   \n",
       "\n",
       "                         t7        t8  \n",
       "convlstm-abcd1234  0.079248  0.070240  \n",
       "convlstm-a8kwo8jx  0.010713  0.007031  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>convlstm-abcd1234</th>\n",
       "      <td>0.197339</td>\n",
       "      <td>0.085128</td>\n",
       "      <td>0.047181</td>\n",
       "      <td>0.030801</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.013780</td>\n",
       "      <td>0.011649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convlstm-a8kwo8jx</th>\n",
       "      <td>0.157186</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.040655</td>\n",
       "      <td>0.022134</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         t1        t2        t3        t4        t5        t6  \\\n",
       "convlstm-abcd1234  0.197339  0.085128  0.047181  0.030801  0.021636  0.016262   \n",
       "convlstm-a8kwo8jx  0.157186  0.076000  0.040655  0.022134  0.011795  0.007272   \n",
       "\n",
       "                         t7        t8  \n",
       "convlstm-abcd1234  0.013780  0.011649  \n",
       "convlstm-a8kwo8jx  0.005036  0.002909  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csi10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>convlstm-abcd1234</th>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.004130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convlstm-a8kwo8jx</th>\n",
       "      <td>0.092310</td>\n",
       "      <td>0.042377</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         t1        t2        t3        t4        t5        t6  \\\n",
       "convlstm-abcd1234  0.120482  0.045346  0.020362  0.012246  0.008627  0.006378   \n",
       "convlstm-a8kwo8jx  0.092310  0.042377  0.022197  0.011640  0.006171  0.004029   \n",
       "\n",
       "                         t7        t8  \n",
       "convlstm-abcd1234  0.005010  0.004130  \n",
       "convlstm-a8kwo8jx  0.002798  0.001618  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csi18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>convlstm-abcd1234</th>\n",
       "      <td>0.112273</td>\n",
       "      <td>0.179575</td>\n",
       "      <td>0.228382</td>\n",
       "      <td>0.269373</td>\n",
       "      <td>0.305903</td>\n",
       "      <td>0.336107</td>\n",
       "      <td>0.362349</td>\n",
       "      <td>0.381351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convlstm-a8kwo8jx</th>\n",
       "      <td>0.314548</td>\n",
       "      <td>0.371742</td>\n",
       "      <td>0.391685</td>\n",
       "      <td>0.397862</td>\n",
       "      <td>0.402602</td>\n",
       "      <td>0.406572</td>\n",
       "      <td>0.410630</td>\n",
       "      <td>0.411008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         t1        t2        t3        t4        t5        t6  \\\n",
       "convlstm-abcd1234  0.112273  0.179575  0.228382  0.269373  0.305903  0.336107   \n",
       "convlstm-a8kwo8jx  0.314548  0.371742  0.391685  0.397862  0.402602  0.406572   \n",
       "\n",
       "                         t7        t8  \n",
       "convlstm-abcd1234  0.362349  0.381351  \n",
       "convlstm-a8kwo8jx  0.410630  0.411008  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lpips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF SCRIPT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irp_rain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
