{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ConvLSTM` Exploration.\n",
    "* The aim of this notebook is to **train** and **validate** a `ConvLSTM()`,  exploring different setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from livelossplot import PlotLosses\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import io\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rainnow.src.convlstm_trainer import save_checkpoint, train, validate, create_eval_loader\n",
    "from rainnow.src.datasets import IMERGDataset\n",
    "from rainnow.src.plotting import plot_training_val_loss, plot_predicted_sequence\n",
    "from rainnow.src.loss import CBLoss, LPIPSMSELoss\n",
    "from rainnow.src.models.conv_lstm import ConvLSTMModel\n",
    "from rainnow.src.normalise import PreProcess\n",
    "from rainnow.src.utilities.loading import load_imerg_datamodule_from_config\n",
    "from rainnow.src.utilities.utils import (\n",
    "    get_device,\n",
    "    transform_0_1_to_minus1_1,\n",
    "    transform_minus1_1_to_0_1,\n",
    ")\n",
    "from rainnow.src.plotting import plot_a_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `helpers.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** DIR helpers **\n",
    "BASE_PATH = \"/teamspace/studios/this_studio\"\n",
    "\n",
    "CKPT_BASE_PATH = f\"{BASE_PATH}/DYffcast/rainnow/results/\"\n",
    "CONFIGS_BASE_PATH = f\"{BASE_PATH}/DYffcast/rainnow/src/dyffusion/configs/\"\n",
    "\n",
    "CKPT_DIR = \"checkpoints\"\n",
    "CKPT_CFG_NAME = \"hparams.yaml\"\n",
    "DATAMODULE_CONFIG_NAME = \"imerg_precipitation.yaml\"\n",
    "# whether or not to get last.ckpt or to get the \"best model\" ckpt (the other one in the folder).\n",
    "GET_LAST = False\n",
    "\n",
    "# ** Dataset Params **\n",
    "REVERSE_PROBABILITY = 0.2  # X% chance to flip the sequence during training.\n",
    "\n",
    "# ** Dataloader Params **\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "INPUT_SEQUENCE_LENGTH = 4\n",
    "OUTPUT_SEQUENCE_LENGTH = 1\n",
    "\n",
    "# ** plotting helpers **\n",
    "# cmap = io.loadmat(\"../../src/utilities/cmaps/colormap.mat\")\n",
    "cmap = io.loadmat(f\"{BASE_PATH}/DYffcast/rainnow/src/utilities/cmaps/colormap.mat\")\n",
    "rain_cmap = ListedColormap(cmap[\"Cmap_rain\"])\n",
    "global_params = {\"font.size\": 8}  # , \"font.family\": \"Times New Roman\"}\n",
    "plt_params = {\"wspace\": 0.1, \"hspace\": 0.15}\n",
    "ylabel_params = {\"ha\": \"right\", \"va\": \"bottom\", \"labelpad\": 1, \"fontsize\": 7.5}\n",
    "\n",
    "# ** get device **\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Datasets & DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = load_imerg_datamodule_from_config(\n",
    "    cfg_base_path=CONFIGS_BASE_PATH,\n",
    "    cfg_name=DATAMODULE_CONFIG_NAME,\n",
    "    overrides={\n",
    "        # \"boxes\": [\"1,0\"],\n",
    "        \"boxes\": [\"0,0\", \"1,0\", \"2,0\", \"2,1\"],\n",
    "        \"window\": 1,\n",
    "        \"horizon\": 8,\n",
    "        \"prediction_horizon\": 8,\n",
    "        \"sequence_dt\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "# get the .data_<split>\n",
    "datamodule.setup(\"train\")\n",
    "datamodule.setup(\"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets.\n",
    "train_dataset = IMERGDataset(\n",
    "    datamodule,\n",
    "    \"train\",\n",
    "    sequence_length=INPUT_SEQUENCE_LENGTH,\n",
    "    target_length=OUTPUT_SEQUENCE_LENGTH,\n",
    ")\n",
    "val_dataset = IMERGDataset(\n",
    "    datamodule, \"validate\", sequence_length=INPUT_SEQUENCE_LENGTH, target_length=OUTPUT_SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "# instantiate the dataloaders.\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train dataset.\n",
    "X_dummy, y_dummy = train_dataset.__getitem__(0)\n",
    "X_dummy.size(), y_dummy.size()\n",
    "\n",
    "assert X_dummy.size() == torch.Size([INPUT_SEQUENCE_LENGTH, 1, 128, 128])\n",
    "assert y_dummy.size() == torch.Size([OUTPUT_SEQUENCE_LENGTH, 1, 128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a batch.\n",
    "dummy_batch = next(iter(train_loader))\n",
    "dummy_inputs, dummy_target = dummy_batch\n",
    "dummy_inputs.size(), dummy_target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_a_sequence(\n",
    "    X=torch.cat([dummy_inputs, dummy_target], dim=1),\n",
    "    b=0,\n",
    "    global_params=global_params,\n",
    "    plot_params={\"cmap\": rain_cmap},\n",
    "    layout_params=plt_params,\n",
    ")\n",
    "plot_a_sequence(\n",
    "    X=torch.cat([dummy_inputs, dummy_target], dim=1),\n",
    "    b=1,\n",
    "    global_params=global_params,\n",
    "    plot_params={\"cmap\": rain_cmap},\n",
    "    layout_params=plt_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** instantiate the preprocesser obj **\n",
    "pprocessor = PreProcess(\n",
    "    percentiles=datamodule.normalization_hparams[\"percentiles\"],\n",
    "    minmax=datamodule.normalization_hparams[\"min_max\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `Training and Val:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Loss Function(s)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ** loss function **\n",
    "# criterion = nn.MSELoss(reduction='mean')\n",
    "# criterion = nn.L1Loss(reduction='mean')\n",
    "# criterion = nn.BCELoss(reduction=\"mean\")\n",
    "# criterion = CBLoss(beta=1.0, data_preprocessor_obj=pprocessor)\n",
    "criterion = LPIPSMSELoss(\n",
    "    alpha=0.6,\n",
    "    model_name=\"alex\",  # trains better with 'alex' - https://github.com/richzhang/PerceptualSimilarity.\n",
    "    reduction=\"mean\",\n",
    "    gamma=1.0,\n",
    "    mse_type=\"cb\",\n",
    "    **{\"beta\": 1, \"data_preprocessor_obj\": pprocessor},\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Instantiate a ConvLSTM()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** instantiate a new model **\n",
    "KERNEL_SIZE = (5, 5)\n",
    "INPUT_DIMS = (1, 128, 128)  # C, H, W\n",
    "OUTPUT_CHANNELS = 1\n",
    "HIDDEN_CHANNELS = [128, 128]\n",
    "NUM_LAYERS = 2\n",
    "CELL_DROPOUT = 0.4  # 0.2\n",
    "OUTPUT_ACTIVATION = nn.Tanh()  # nn.Tanh()  # nn.Sigmoid() # nn.Tanh() # nn.Sigmoid()\n",
    "\n",
    "model = ConvLSTMModel(\n",
    "    input_sequence_length=INPUT_SEQUENCE_LENGTH,\n",
    "    output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
    "    input_dims=INPUT_DIMS,\n",
    "    hidden_channels=HIDDEN_CHANNELS,\n",
    "    output_channels=OUTPUT_CHANNELS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    output_activation=OUTPUT_ACTIVATION,\n",
    "    apply_batchnorm=True,\n",
    "    cell_dropout=CELL_DROPOUT,\n",
    "    bias=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a checkpoint.\n",
    "model_save_path = \"convlstm-abcd1234.pt\"  # (old best) LCB\n",
    "model.load_state_dict(\n",
    "    state_dict=torch.load(model_save_path, map_location=torch.device(device))[\"model_state_dict\"]\n",
    ")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ** training params 101 **\n",
    "n_epochs = 12\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=7e-5, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=5)\n",
    "use_liveloss = True\n",
    "\n",
    "# model ckpt save path.\n",
    "model_save_path = f\"conv_lstm_hc_{''.join([str(i) for i in HIDDEN_CHANNELS])}_ks_{KERNEL_SIZE[0]}_oa_{str(OUTPUT_ACTIVATION)[:-2]}_dummy.pt\"\n",
    "\n",
    "liveloss = PlotLosses()\n",
    "train_losses, val_losses = [], []\n",
    "with tqdm(total=len(train_loader) * n_epochs, desc=\"Training\", unit=\"batch\") as tepoch:\n",
    "    for i in range(n_epochs):\n",
    "        logs = {}\n",
    "        train_loss = train(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            tepoch=tepoch,\n",
    "            curr_epoch=i,\n",
    "            n_epochs=n_epochs,\n",
    "            device=device,\n",
    "            log_training=True,\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        logs[\"loss\"] = train_loss\n",
    "\n",
    "        if val_loader:\n",
    "            val_loss = validate(\n",
    "                model=model,\n",
    "                data_loader=val_loader,\n",
    "                device=device,\n",
    "                criterion=criterion,\n",
    "            )\n",
    "            val_losses.append(val_loss)\n",
    "            logs[\"val_loss\"] = val_loss\n",
    "\n",
    "        if use_liveloss:\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()\n",
    "\n",
    "        # save a model checkpoint.\n",
    "        if model_save_path:\n",
    "            # save 'best' val loss checkpoint.\n",
    "            if val_loss <= min(val_losses, default=float(\"inf\")):\n",
    "                save_checkpoint(\n",
    "                    model_weights=model.state_dict(),\n",
    "                    optimizer_info=optimizer.state_dict(),\n",
    "                    model_save_path=model_save_path,\n",
    "                    epoch=i,\n",
    "                    train_loss=train_loss,\n",
    "                    val_loss=val_loss,\n",
    "                )\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(train_losses[-1])\n",
    "\n",
    "    # save the last epoch.\n",
    "    save_checkpoint(\n",
    "        model_weights=model.state_dict(),\n",
    "        optimizer_info=optimizer.state_dict(),\n",
    "        model_save_path=model_save_path[:-3] + \"_last.pt\",\n",
    "        epoch=i,\n",
    "        train_loss=train_loss,\n",
    "        val_loss=val_loss,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `create Predict dataloader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup(\"predict\")\n",
    "\n",
    "predict_dataset = IMERGDataset(\n",
    "    datamodule, \"predict\", sequence_length=INPUT_SEQUENCE_LENGTH, target_length=OUTPUT_SEQUENCE_LENGTH\n",
    ")\n",
    "predict_loader = DataLoader(\n",
    "    dataset=predict_dataset, batch_size=6, num_workers=NUM_WORKERS, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Eval predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** create the eval dataloader **\n",
    "eval_loader, _ = create_eval_loader(\n",
    "    data_loader=predict_loader, horizon=8, input_sequence_length=4, img_dims=(128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Load in 'best' model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the checkpoint from in-line NB training & set to eval() mode.\n",
    "model_save_path = f\"conv_lstm_hc_{''.join([str(i) for i in HIDDEN_CHANNELS])}_ks_{KERNEL_SIZE[0]}_oa_{str(OUTPUT_ACTIVATION)[:-2]}_dummy.pt\"\n",
    "\n",
    "# ** BCE **\n",
    "# model_save_path = \"conv_lstm_k34y14il.pt\"  # BCE.\n",
    "# model_save_path = \"convlstm-a8kwo8jx.pt\"   # old.\n",
    "\n",
    "# ** LCB **\n",
    "# model_save_path = \"convlstm-abcd1234.pt\" # (old best) LCB\n",
    "# model_save_path = \"conv_lstm_f1dlb0m7.pt\"  # LCB 30E LCB\n",
    "# model_save_path = \"conv_lstm_9h86gnt5.pt\" # 10E large batch size LCB\n",
    "# model_save_path = \"conv_lstm_wwj6eryz.pt\" # recent 10E.\n",
    "# model_save_path = \"conv_lstm_i93g6pzb.pt\"\n",
    "\n",
    "model.load_state_dict(\n",
    "    state_dict=torch.load(model_save_path, map_location=torch.device(device))[\"model_state_dict\"]\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for e, (X, target) in enumerate(eval_loader):\n",
    "        predictions = {}\n",
    "        # predict t+1\n",
    "        _input = X.clone().unsqueeze(0).to(device)\n",
    "\n",
    "        for t in range(target.size(0)):\n",
    "            pred = model(_input)\n",
    "            if isinstance(model.output_activation, nn.Tanh):\n",
    "                pred = transform_minus1_1_to_0_1(pred)\n",
    "\n",
    "            predictions[f\"t{t+1}\"] = pred.squeeze(0)\n",
    "\n",
    "            # update the inputs with the last pred.\n",
    "            _input = torch.concat([_input[:, 1:, ...], pred], dim=1)\n",
    "\n",
    "        results.append([target, predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "figsize = (14, 4)\n",
    "plot_params = {\"cmap\": rain_cmap, \"vmin\": 0.1, \"vmax\": 18}\n",
    "\n",
    "idx = 32  # 19 is the paper case study image.\n",
    "\n",
    "targets, predictions = results[idx]\n",
    "targets = targets.cpu().detach()\n",
    "predictions = {k: v.cpu().detach() for k, v in predictions.items()}\n",
    "\n",
    "# get raw scale.\n",
    "target_reversed = pprocessor.reverse_processing(targets)\n",
    "preds_reversed = {k: pprocessor.reverse_processing(v) for k, v in predictions.items()}\n",
    "\n",
    "fig, axs = plt.subplots(2, targets.size(0), figsize=figsize)\n",
    "plt.rcParams.update(global_params)\n",
    "# plot ground truth in the 1st row.\n",
    "for j in range(targets.size(0)):\n",
    "    axs[0, j].imshow(targets[j, c, ...], **{\"cmap\": rain_cmap})\n",
    "    axs[0, j].set_title(f\"Ground Truth: x_t+{j}\")\n",
    "# plot predictions.\n",
    "for e, (k, pred) in enumerate(predictions.items()):\n",
    "    axs[1, e].imshow(pred[0, c, :, :], **{\"cmap\": rain_cmap})\n",
    "    axs[1, e].set_title(f\"{k}\")\n",
    "for ax in axs.flatten():\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# raw scale.\n",
    "fig, axs = plt.subplots(2, targets.size(0), figsize=figsize)\n",
    "plt.rcParams.update(global_params)\n",
    "# plot ground truth in the 1st row.\n",
    "for j in range(targets.size(0)):\n",
    "    axs[0, j].imshow(target_reversed[j, c, ...], **plot_params)\n",
    "    axs[0, j].set_title(f\"Ground Truth: x_t+{j}\")\n",
    "# plot predictions.\n",
    "for e, (k, pred) in enumerate(preds_reversed.items()):\n",
    "    axs[1, e].imshow(pred[0, c, :, :], **plot_params)\n",
    "    axs[1, e].set_title(f\"{k}\")\n",
    "for ax in axs.flatten():\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF SCRIPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irp_rain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
